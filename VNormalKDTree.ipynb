{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T19:25:49.352794Z",
     "start_time": "2025-04-23T19:25:48.610442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from stl import mesh\n",
    "from sklearn.neighbors import KDTree\n",
    "from collections import defaultdict\n",
    "stl_file = \"space_station/meshes/base_link.STL\" \n",
    "ss_mesh = mesh.Mesh.from_file(stl_file)\n"
   ],
   "id": "6ada6ab9000cb14a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Find unique vertices and their area-weighted normals.",
   "id": "6ff282d5b9eaeab4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-23T19:25:50.658124Z",
     "start_time": "2025-04-23T19:25:50.642459Z"
    }
   },
   "source": [
    "unique_vertices = np.unique(ss_mesh.vectors.reshape(-1, 3), axis=0)\n",
    "vertex_normals = defaultdict(list)\n",
    "\n",
    "for i, (normal, triangle) in enumerate(zip(ss_mesh.normals, ss_mesh.vectors)):\n",
    "    for vertex in triangle:\n",
    "        vertex_tuple = tuple(vertex)  # Convert to tuple for defaultdict key\n",
    "        if np.linalg.norm(normal) > 0.0:\n",
    "            normal /= np.linalg.norm(normal)\n",
    "        vertex_normals[vertex_tuple].append(normal*ss_mesh.areas[i])\n",
    "\n",
    "# Calculate the average normal for each vertex\n",
    "average_vertex_normals = {}\n",
    "for vertex, normals in vertex_normals.items():\n",
    "    #add the weighted contributions from the triangles surrounding each vertex\n",
    "    average_normal = np.sum(normals, axis=0)\n",
    "    # Normalize to divide by the sum of the weighted normals\n",
    "    norm = np.linalg.norm(average_normal)\n",
    "    if norm > 1e-6:  # Avoid division by zero\n",
    "        average_vertex_normals[vertex] = average_normal / norm\n",
    "    else:\n",
    "        average_vertex_normals[vertex] = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "# Convert the dictionaries to lists of (vertex, average_normal) if needed\n",
    "vertex_normal_list = [(np.array(v), n) for v, n in average_vertex_normals.items()]\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Use this to create viewpoints.",
   "id": "6fe3c1aeb7501699"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T19:29:07.108672Z",
     "start_time": "2025-04-23T19:29:07.105897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "view_distance = 0.2\n",
    "vps = [v + view_distance*n for v, n in average_vertex_normals.items()]\n",
    "vps = np.array(vps)\n",
    "#print(vps)"
   ],
   "id": "2a3ad08cb386c505",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.20507038e-01  2.03938901e-01  2.48679668e-01]\n",
      " [-6.85978532e-01  1.16620392e-01 -3.77653167e-02]\n",
      " [-5.12115896e-01 -2.04612598e-01  2.47279257e-01]\n",
      " [-6.85469925e-01 -1.05695494e-01 -4.99430262e-02]\n",
      " [-5.10322332e-01 -2.04731047e-01  1.75066543e+00]\n",
      " [-6.85978532e-01 -1.16620392e-01  2.03776526e+00]\n",
      " [-5.06064534e-01  2.04902619e-01  1.75136459e+00]\n",
      " [-6.85469925e-01  1.05695494e-01  2.04994297e+00]\n",
      " [-6.37990177e-01 -2.80977845e-01 -3.28431204e-02]\n",
      " [-6.30143642e-01 -2.98159450e-01  2.03284311e+00]\n",
      " [-5.32986522e-01 -4.49338883e-01 -3.28431241e-02]\n",
      " [-5.20617187e-01 -4.63613868e-01  2.03284311e+00]\n",
      " [-3.84803414e-01 -5.81297159e-01 -3.28431204e-02]\n",
      " [-3.68913382e-01 -5.91509044e-01  2.03284311e+00]\n",
      " [-2.05445826e-01 -6.66162193e-01 -3.28431167e-02]\n",
      " [-1.87322438e-01 -6.71483696e-01  2.03284311e+00]\n",
      " [-9.57422983e-03 -6.99770689e-01  3.06151588e-17]\n",
      " [ 9.44425259e-03 -6.97058737e-01  2.03284311e+00]\n",
      " [ 1.87322438e-01 -6.71483696e-01 -3.28431167e-02]\n",
      " [ 2.05445826e-01 -6.66162193e-01  2.03284311e+00]\n",
      " [ 3.68913382e-01 -5.91509044e-01 -3.28431204e-02]\n",
      " [ 3.84803414e-01 -5.81297159e-01  2.03284311e+00]\n",
      " [ 5.20617187e-01 -4.63613868e-01 -3.28431241e-02]\n",
      " [ 5.32986522e-01 -4.49338883e-01  2.03284311e+00]\n",
      " [ 6.30143642e-01 -2.98159450e-01 -3.28431241e-02]\n",
      " [ 6.37990177e-01 -2.80977845e-01  2.03284311e+00]\n",
      " [ 6.85978532e-01 -1.16620384e-01 -3.77653092e-02]\n",
      " [ 6.85469925e-01 -1.05695486e-01  2.04994297e+00]\n",
      " [ 6.85469925e-01  1.05695494e-01 -4.99430187e-02]\n",
      " [ 5.06064653e-01  2.04906031e-01  2.49300554e-01]\n",
      " [ 5.10322154e-01 -2.04727754e-01  2.48671472e-01]\n",
      " [ 5.12116730e-01 -2.04626247e-01  1.75139451e+00]\n",
      " [ 6.85978532e-01  1.16620384e-01  2.03776526e+00]\n",
      " [ 5.20505726e-01  2.03925967e-01  1.75263608e+00]\n",
      " [-6.37990177e-01  2.80977845e-01  2.03284311e+00]\n",
      " [-6.30143642e-01  2.98159450e-01 -3.28431241e-02]\n",
      " [-5.32986522e-01  4.49338883e-01  2.03284311e+00]\n",
      " [-5.20617187e-01  4.63613868e-01 -3.28431241e-02]\n",
      " [-3.84803414e-01  5.81297159e-01  2.03284311e+00]\n",
      " [-3.68913382e-01  5.91509044e-01 -3.28431204e-02]\n",
      " [-2.05445826e-01  6.66162193e-01  2.03284311e+00]\n",
      " [-1.87322438e-01  6.71483696e-01 -3.28431167e-02]\n",
      " [-9.44425445e-03  6.97058737e-01  2.03284311e+00]\n",
      " [ 9.44425259e-03  6.97058737e-01 -3.28431204e-02]\n",
      " [ 1.87322438e-01  6.71483696e-01  2.03284311e+00]\n",
      " [ 2.05445826e-01  6.66162193e-01 -3.28431167e-02]\n",
      " [ 3.68913382e-01  5.91509044e-01  2.03284311e+00]\n",
      " [ 3.84803414e-01  5.81297159e-01 -3.28431204e-02]\n",
      " [ 5.20617187e-01  4.63613868e-01  2.03284311e+00]\n",
      " [ 5.32986522e-01  4.49338883e-01 -3.28431241e-02]\n",
      " [ 6.30143642e-01  2.98159450e-01  2.03284311e+00]\n",
      " [ 6.37990177e-01  2.80977845e-01 -3.28431167e-02]\n",
      " [ 0.00000000e+00  1.22460635e-16  2.20000005e+00]\n",
      " [ 1.83697015e-16 -5.00000000e-01 -2.00000003e-01]\n",
      " [-5.33827105e-26 -1.22460607e-17 -2.00000003e-01]\n",
      " [ 2.00266623e+00 -2.04977766e-01  2.48666808e-01]\n",
      " [ 2.00066662e+00 -2.04994440e-01  1.75133324e+00]\n",
      " [ 2.00133324e+00  2.04994440e-01  1.75066662e+00]\n",
      " [ 2.00133324e+00  2.04977766e-01  2.47333631e-01]\n",
      " [-2.00266623e+00 -2.04964444e-01  1.75266623e+00]\n",
      " [-2.00066662e+00 -2.04997763e-01  2.49333337e-01]\n",
      " [-2.00133324e+00  2.04991087e-01  2.48666734e-01]\n",
      " [-2.00133324e+00  2.04991087e-01  1.75133324e+00]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T19:34:51.688560Z",
     "start_time": "2025-04-23T19:34:51.681248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def kd_filtering(viewpoints, normals):# --- Parameters ---\n",
    "    spatial_threshold = 0.5    # Maximum distance for points to be considered \"too close\"\n",
    "    normal_threshold = 0.1     # Maximum np.linalg.norm(np.cross(n1, n2)) for normals to be \"too close\"\n",
    "    \n",
    "    # --- Filtering Implementation ---\n",
    "    filtered_points_list = []\n",
    "    filtered_normals_list = []\n",
    "    # Store the filtered points as a NumPy array for KD-Tree building\n",
    "    # Initialize with an empty array of shape (0, 3)\n",
    "    filtered_points_array = np.empty((0, 3))\n",
    "    filtered_kdtree = None # KD-Tree will be built on filtered_points_array\n",
    "    \n",
    "    num_viewpoints = len(viewpoints)\n",
    "    \n",
    "    # Iterate through each original point\n",
    "    for i in range(num_viewpoints):\n",
    "        query_point = viewpoints[i]\n",
    "        query_normal = normals[i]\n",
    "    \n",
    "        is_redundant = False # Assume we want to keep it until proven otherwise\n",
    "    \n",
    "        # Check against points ALREADY added to the filtered list\n",
    "        if len(filtered_points_list) > 0:\n",
    "            # Build KD-tree on the *currently filtered* points\n",
    "            # This rebuilds the tree in each iteration, which is inefficient for large datasets\n",
    "            # A better approach for large scale would be to use a structure that supports\n",
    "            # incremental updates or a different sampling strategy.\n",
    "            # However, for demonstrating the logic with KD-tree on filtered points, this works.\n",
    "            filtered_kdtree = KDTree(filtered_points_array)\n",
    "    \n",
    "            # Query the KD-tree of *filtered* points for neighbors of the current point\n",
    "            # within the spatial threshold.\n",
    "            # query_point needs to be (1, 3)\n",
    "            kept_neighbor_indices = filtered_kdtree.query_radius(query_point.reshape(1, -1), r=spatial_threshold)[0]\n",
    "    \n",
    "            # If there are any filtered points within the spatial radius\n",
    "            if len(kept_neighbor_indices) > 0:\n",
    "                # Now check the normal similarity against these spatially close *filtered* points\n",
    "                for filtered_idx in kept_neighbor_indices:\n",
    "                    kept_point = filtered_points_list[filtered_idx] # Get the point from the filtered list\n",
    "                    kept_normal = filtered_normals_list[filtered_idx] # Get the normal from the filtered list\n",
    "    \n",
    "                    normal_angle_metric = np.linalg.norm(np.cross(query_normal, kept_normal))\n",
    "    \n",
    "                    if normal_angle_metric < normal_threshold:\n",
    "                        # Found a spatially close *and* normal-similar point that was already kept\n",
    "                        is_redundant = True\n",
    "                        break # No need to check other kept neighbors for this point i\n",
    "    \n",
    "        # If the point is not redundant (i.e., not too close to any already kept point)\n",
    "        if not is_redundant:\n",
    "            # Add the current point and normal to the filtered lists\n",
    "            filtered_points_list.append(query_point)\n",
    "            filtered_normals_list.append(query_normal)\n",
    "            # Update the array used for the next KD-tree build\n",
    "            filtered_points_array = np.array(filtered_points_list)\n",
    "    \n",
    "    \n",
    "    # Convert the final lists to NumPy arrays\n",
    "    final_filtered_points = np.array(filtered_points_list)\n",
    "    final_filtered_normals = np.array(filtered_normals_list)\n",
    "    \n",
    "    print(f\"\\nOriginal number of points: {num_viewpoints}\")\n",
    "    print(f\"Filtered number of points: {len(final_filtered_points)}\")\n",
    "    print(f\"Reduction: {num_viewpoints - len(final_filtered_points)}\")\n",
    "    \n",
    "    # --- Returning the filtered points and normals ---\n",
    "    return final_filtered_points, final_filtered_normals"
   ],
   "id": "5531d29cc03bb80a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T19:34:52.427433Z",
     "start_time": "2025-04-23T19:34:52.418386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#vertex_norms = np.array(average_vertex_normals.value\n",
    "vertex_norms = [n for n in average_vertex_normals.values()]\n",
    "pts, norms = kd_filtering(vps, vertex_norms)"
   ],
   "id": "3f3903ee98bbcfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original number of points: 63\n",
      "Filtered number of points: 56\n",
      "Reduction: 7\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fe1a619616e5aafe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
